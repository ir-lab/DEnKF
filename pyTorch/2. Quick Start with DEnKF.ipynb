{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0254d1b",
   "metadata": {},
   "source": [
    "## DEnKF\n",
    "In this project, we avoid the separation of modeling process noise and state transition by using recent insights in stochastic neural networks (SNNs). More specifically, a theoretical link between the Dropout training algorithm and Bayesian inference in deep Gaussian processes. Accordingly, after training a neural network with Dropout, it is possible to generate empirical samples from the predictive posterior via stochastic forward passes.\n",
    "\n",
    "Hence, for the purposes of filtering, we can implicitly model the process noise by sampling state from a neural network trained on the transition dynamics, i.e., ${\\bf x}_{t}  \\thicksim  f_{\\pmb {\\theta}} ({\\bf x}_{t-1})$. In contrast to previous approaches, the transition network $f_{\\pmb {\\theta}}(\\cdot)$ models the system dynamics, as well as the inherent noise model in a consistent fashion without imposing diagonality. We formulate DEnKF as an extension of the EnKF while keeping the core algorithmic steps intact. \n",
    "In particular, we use an initial ensemble of $E$ members to represent the initial state distribution ${\\bf X}_0 = [ {\\bf x}^{1}_0, \\dots, {\\bf x}^{E}_0]$, $E \\in \\mathbb{Z}^+$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c95a89",
   "metadata": {},
   "source": [
    "### 1. Prediction Step\n",
    "We leverage the stochastic forward passes from a trained state transition model to update each ensemble member: \n",
    "\n",
    "\\begin{aligned}\n",
    "    {\\bf x}^{i}_{t|t-1} & \\thicksim  f_{\\pmb {\\theta}} ({\\bf x}^{i}_{t|t-1}|{\\bf x}^{i}_{t-1|t-1}),\\  \\forall i \\in E.\n",
    "\\end{aligned}\n",
    "\n",
    "Matrix ${\\bf X}_{t|t-1} = [{\\bf x}^{1}_{t|t-1}, \\cdots, {\\bf x}^{E}_{t|t-1}]$ holds the updated ensemble members which are propagated one step forward through the state space. Note that sampling from the transition model $f_{\\pmb {\\theta}}(\\cdot)$ (using the SNN methodology described above) implicitly introduces a process noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from bayesian_torch.layers.flipout_layers.linear_flipout import LinearFlipout\n",
    "import torchvision.models as models\n",
    "from einops import rearrange, repeat\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ProcessModel(nn.Module):\n",
    "    \"\"\"\n",
    "    process model takes a state or a stack of states (t-n:t-1) and\n",
    "    predict the next state t. the process model is flexiable, we can inject the known\n",
    "    dynamics into it, we can also change the model architecture which takes sequential\n",
    "    data as input\n",
    "\n",
    "    input -> [batch_size, num_ensemble, dim_x]\n",
    "    output ->  [batch_size, num_ensemble, dim_x]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_ensemble, dim_x):\n",
    "        super(ProcessModel, self).__init__()\n",
    "        self.num_ensemble = num_ensemble\n",
    "        self.dim_x = dim_x\n",
    "\n",
    "        self.bayes1 = LinearFlipout(in_features=self.dim_x, out_features=64)\n",
    "        self.bayes2 = LinearFlipout(in_features=64, out_features=512)\n",
    "        self.bayes3 = LinearFlipout(in_features=512, out_features=256)\n",
    "        self.bayes4 = LinearFlipout(in_features=256, out_features=self.dim_x)\n",
    "\n",
    "    def forward(self, last_state):\n",
    "        batch_size = last_state.shape[0]\n",
    "        last_state = rearrange(\n",
    "            last_state, \"bs k dim -> (bs k) dim\", bs=batch_size, k=self.num_ensemble\n",
    "        )\n",
    "        x, _ = self.bayes1(last_state)\n",
    "        x = F.relu(x)\n",
    "        x, _ = self.bayes2(x)\n",
    "        x = F.relu(x)\n",
    "        x, _ = self.bayes3(x)\n",
    "        x = F.relu(x)\n",
    "        update, _ = self.bayes4(x)\n",
    "        state = last_state + update\n",
    "        state = rearrange(\n",
    "            state, \"(bs k) dim -> bs k dim\", bs=batch_size, k=self.num_ensemble\n",
    "        )\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b9f4c",
   "metadata": {},
   "source": [
    "### 2. Update Step \n",
    "Given the updated ensemble members ${\\bf X}_{t|t-1}$, a nonlinear observation model $h_{\\pmb {\\psi}}(\\cdot)$ is applied to transform the ensemble members from the state space to observation space. Following our main rationale, the observation model is realized via a neural network with weights $\\pmb {\\psi}$. Accordingly, the update equations for the EnKF become:\n",
    "    \\begin{align}\n",
    "    \\label{eq:2}\n",
    "        {\\bf H}_t {\\bf X}_{t|t-1} &= \\left[ h_{\\pmb {\\psi}}({\\bf x}^1_{t|t-1}), \\cdots, h_{\\pmb {\\psi}}({\\bf x}^E_{t|t-1}) \\right],\\\\\n",
    "        \\label{eq:3}\n",
    "        {\\bf H}_t {\\bf A}_{t} &=  {\\bf H}_t {\\bf X}_{t|t-1} \\\\\n",
    "        &- \\left[\\frac{1}{E} \\sum_{i=1}^E h_{\\pmb {\\psi}}({\\bf x}^i_{t|t-1}),\n",
    "        \\cdots,\n",
    "        \\frac{1}{E} \\sum_{i=1}^E h_{\\pmb {\\psi}}({\\bf x}^i_{t|t-1})\\right]. \\nonumber\n",
    "    \\end{align}\n",
    "${\\bf H}_t {\\bf X}_{t|t-1}$ is the predicted observation, and ${\\bf H}_t {\\bf A}_{t}$ is the sample mean of the predicted observation at $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587e0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    observation model takes a predicted state at t-1 and\n",
    "    predict the corresponding oberservations. typically, the observation is part of the\n",
    "    state (H as an identity matrix), unless we are using some observations indirectly to\n",
    "    update the state\n",
    "\n",
    "    input -> [batch_size, num_ensemble, dim_x]\n",
    "    output ->  [batch_size, num_ensemble, dim_z]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_ensemble, dim_x, dim_z):\n",
    "        super(ObservationModel, self).__init__()\n",
    "        self.num_ensemble = num_ensemble\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_z = dim_z\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(self.dim_x, 64)\n",
    "        self.linear2 = torch.nn.Linear(64, 128)\n",
    "        self.linear3 = torch.nn.Linear(128, 128)\n",
    "        self.linear4 = torch.nn.Linear(128, 64)\n",
    "        self.linear5 = torch.nn.Linear(64, self.dim_z)\n",
    "\n",
    "    def forward(self, state):\n",
    "        batch_size = state.shape[0]\n",
    "        state = rearrange(\n",
    "            state, \"bs k dim -> (bs k) dim\", bs=batch_size, k=self.num_ensemble\n",
    "        )\n",
    "        x = self.linear1(state)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        x = F.relu(x)\n",
    "        z_pred = self.linear5(x)\n",
    "        z_pred = rearrange(\n",
    "            z_pred, \"(bs k) dim -> bs k dim\", bs=batch_size, k=self.num_ensemble\n",
    "        )\n",
    "        return z_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f0e44",
   "metadata": {},
   "source": [
    "EnKF treats observations as random variables. Hence, the ensemble can incorporate a measurement perturbed by a small stochastic noise thereby accurately reflecting the error covariance of the best state estimate. \n",
    "In our differentiable version of the EnKF, we also incorporate a sensor model which can learn projections between a latent space and higher-dimensional observations spaces, i.e. images. To this end, we leverage the methodology from SNN to train a stochastic sensor model $s_{\\pmb {\\xi}}(\\cdot)$:\n",
    "\\begin{aligned}\\label{eq:sensor}\n",
    "      \\tilde{{\\bf y}}^{i}_t & \\thicksim  s_{\\pmb {\\xi}} (\\tilde{{\\bf y}}^{i}_t|{\\bf y}_{t}),\\  \\forall i \\in E.\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "where ${\\bf y}_{t}$ represents the noisy observation. Sampling yields observations $\\tilde{{\\bf Y}}_t = [\\tilde{{\\bf y}}^{1}_t, \\cdots, \\tilde{{\\bf y}}^{E}_t]$ and sample mean $\\tilde{{\\bf y}}_t = \\frac{1}{E}\\sum_{i=1}^i\\tilde{{\\bf y}}^i_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e2c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgSensorModel(nn.Module):\n",
    "    \"\"\"\n",
    "    latent sensor model takes the inputs stacks of images t-n:t-1\n",
    "    and generate the latent state representations for the transformer\n",
    "    process model, here we use resnet34 as the basic encoder to project\n",
    "    down the vision inputs\n",
    "\n",
    "    images -> [batch, channels, height, width]\n",
    "    out -> [batch, ensemble, latent_dim_x]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_ensemble, dim_x):\n",
    "        super(imgSensorModel, self).__init__()\n",
    "        self.num_ensemble = num_ensemble\n",
    "        self.dim_x = dim_x\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            torch.nn.Dropout(p=0.1),\n",
    "        )\n",
    "        self.linear1 = torch.nn.Linear(64 * 7 * 7, 512)\n",
    "        self.bayes1 = LinearFlipout(in_features=512, out_features=64)\n",
    "        self.bayes2 = LinearFlipout(in_features=64, out_features=dim_x)\n",
    "\n",
    "    def forward(self, images):\n",
    "        batch_size = images.shape[0]\n",
    "        x = images\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = repeat(x, \"bs dim -> bs en dim\", en=self.num_ensemble)\n",
    "        x = rearrange(x, \"bs k dim -> (bs k) dim\")\n",
    "        x, _ = self.bayes1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        encoding = x\n",
    "        obs, _ = self.bayes2(x)\n",
    "        obs = rearrange(\n",
    "            obs, \"(bs k) dim -> bs k dim\", bs=batch_size, k=self.num_ensemble\n",
    "        )\n",
    "        obs_z = torch.mean(obs, axis=1)\n",
    "        obs_z = rearrange(obs_z, \"bs (k dim) -> bs k dim\", k=1)\n",
    "        encoding = rearrange(\n",
    "            encoding, \"(bs k) dim -> bs k dim\", bs=batch_size, k=self.num_ensemble\n",
    "        )\n",
    "        encoding = torch.mean(encoding, axis=1)\n",
    "        encoding = rearrange(encoding, \"(bs k) dim -> bs k dim\", bs=batch_size, k=1)\n",
    "\n",
    "        return obs, obs_z, encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fbc89",
   "metadata": {},
   "source": [
    "The innovation covariance ${\\bf S}_t$ can then be calculated as:\n",
    "\n",
    "\\begin{aligned}\n",
    "        {\\bf S}_t &= \\frac{1}{E-1}  ({\\bf H}_t {\\bf A}_t)  ({\\bf H}_t {\\bf A}_t)^T + r_{\\pmb {\\zeta}}(\\tilde{{\\bf y}_t}).\n",
    "\\end{aligned}\n",
    "\n",
    "where $r_{\\pmb {\\zeta}}(\\cdot)$ is the measurement noise model implemented using MLP. $r_{\\pmb {\\zeta}}(\\cdot)$ takes an learned observation $\\tilde{{\\bf y}_t}$ in time $t$ and provides stochastic noise in the observation space by constructing the diagonal of the noise covariance matrix. The final estimate of the ensemble ${\\bf X}_{t|t}$ can be obtained by performing the measurement update step:\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf A}_t &= {\\bf X}_{t|t-1} - \\frac{1}{E}\\sum_{i=1}^E{\\bf x}^i_{t|t-1},\\\\\n",
    "{\\bf K}_t &= \\frac{1}{E-1} {\\bf A}_t ({\\bf H}_t {\\bf A}_t)^T {\\bf S}_t^{-1},\\\\\n",
    "{\\bf X}_{t|t} &= {\\bf X}_{t|t-1} + {\\bf K}_t (\\tilde{{\\bf Y}}_t - {\\bf H}_t {\\bf X}_{t|t-1}),\n",
    "\\end{align}\n",
    "    \n",
    "where ${\\bf K}_t$ is the Kalman gain. In inference, the ensemble mean ${\\bf \\bar{x}}_{t|t} = \\frac{1}{E}\\sum_{i=1}^E {\\bf x}^i_{t|t}$ is used as the updated state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a976d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationNoise(nn.Module):\n",
    "    def __init__(self, dim_z, r_diag):\n",
    "        \"\"\"\n",
    "        observation noise model is used to learn the observation noise covariance matrix\n",
    "        R from the learned observation, kalman filter require a explicit matrix for R\n",
    "        therefore we construct the diag of R to model the noise here\n",
    "\n",
    "        input -> [batch_size, 1, encoding/dim_z]\n",
    "        output -> [batch_size, dim_z, dim_z]\n",
    "        \"\"\"\n",
    "        super(ObservationNoise, self).__init__()\n",
    "        self.dim_z = dim_z\n",
    "        self.r_diag = r_diag\n",
    "\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, self.dim_z)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        batch_size = inputs.shape[0]\n",
    "        constant = np.ones(self.dim_z) * 1e-3\n",
    "        init = np.sqrt(np.square(self.r_diag) - constant)\n",
    "        diag = self.fc1(inputs)\n",
    "        diag = F.relu(diag)\n",
    "        diag = self.fc2(diag)\n",
    "        diag = torch.square(diag + torch.Tensor(constant).to(device)) + torch.Tensor(\n",
    "            init\n",
    "        ).to(device)\n",
    "        diag = rearrange(diag, \"bs k dim -> (bs k) dim\")\n",
    "        R = torch.diag_embed(diag)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea817c4c",
   "metadata": {},
   "source": [
    "### 3. DEnKF with all subclass\n",
    "DEnKF contains four sub-modules: a state transition model, an observation model, an observation noise model, and a sensor model. The entire framework is implemented as a final class which is then used for end-to-end training.\n",
    "The same implementation can also be found in `PyTorch/model/DEnKF.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715a0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEnKF(nn.Module):\n",
    "    def __init__(self, num_ensemble, dim_x, dim_z):\n",
    "        super(DEnKF, self).__init__()\n",
    "        self.num_ensemble = num_ensemble\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_z = dim_z\n",
    "        self.r_diag = np.ones((self.dim_z)).astype(np.float32) * 0.1\n",
    "        self.r_diag = self.r_diag.astype(np.float32)\n",
    "\n",
    "        # instantiate model\n",
    "        self.process_model = ProcessModel(self.num_ensemble, self.dim_x)\n",
    "        self.observation_model = ObservationModel(\n",
    "            self.num_ensemble, self.dim_x, self.dim_z\n",
    "        )\n",
    "        self.observation_noise = ObservationNoise(self.dim_z, self.r_diag)\n",
    "        self.sensor_model = imgSensorModel(self.num_ensemble, self.dim_z)\n",
    "\n",
    "    def forward(self, inputs, states):\n",
    "        # decompose inputs and states\n",
    "        batch_size = inputs[0].shape[0]\n",
    "        raw_obs = inputs\n",
    "        state_old, m_state = states\n",
    "\n",
    "        ##### prediction step #####\n",
    "        state_pred = self.process_model(state_old)\n",
    "        m_A = torch.mean(state_pred, axis=1)\n",
    "        mean_A = repeat(m_A, \"bs dim -> bs k dim\", k=self.num_ensemble)\n",
    "        A = state_pred - mean_A\n",
    "        A = rearrange(A, \"bs k dim -> bs dim k\")\n",
    "\n",
    "        ##### update step #####\n",
    "        H_X = self.observation_model(state_pred)\n",
    "        mean = torch.mean(H_X, axis=1)\n",
    "        H_X_mean = rearrange(mean, \"bs (k dim) -> bs k dim\", k=1)\n",
    "        m = repeat(mean, \"bs dim -> bs k dim\", k=self.num_ensemble)\n",
    "        H_A = H_X - m\n",
    "        # transpose operation\n",
    "        H_XT = rearrange(H_X, \"bs k dim -> bs dim k\")\n",
    "        H_AT = rearrange(H_A, \"bs k dim -> bs dim k\")\n",
    "\n",
    "        # get learned observation\n",
    "        ensemble_z, z, encoding = self.sensor_model(raw_obs)\n",
    "        y = rearrange(ensemble_z, \"bs k dim -> bs dim k\")\n",
    "        R = self.observation_noise(encoding)\n",
    "\n",
    "        # measurement update\n",
    "        innovation = (1 / (self.num_ensemble - 1)) * torch.matmul(H_AT, H_A) + R\n",
    "        inv_innovation = torch.linalg.inv(innovation)\n",
    "        K = (1 / (self.num_ensemble - 1)) * torch.matmul(\n",
    "            torch.matmul(A, H_A), inv_innovation\n",
    "        )\n",
    "        gain = rearrange(torch.matmul(K, y - H_XT), \"bs dim k -> bs k dim\")\n",
    "        state_new = state_pred + gain\n",
    "\n",
    "        # gather output\n",
    "        m_state_new = torch.mean(state_new, axis=1)\n",
    "        m_state_new = rearrange(m_state_new, \"bs (k dim) -> bs k dim\", k=1)\n",
    "        m_state_pred = rearrange(m_A, \"bs (k dim) -> bs k dim\", k=1)\n",
    "        output = (\n",
    "            state_new.to(dtype=torch.float32),\n",
    "            m_state_new.to(dtype=torch.float32),\n",
    "            m_state_pred.to(dtype=torch.float32),\n",
    "            z.to(dtype=torch.float32),\n",
    "            ensemble_z.to(dtype=torch.float32),\n",
    "            H_X_mean.to(dtype=torch.float32),\n",
    "        )\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
